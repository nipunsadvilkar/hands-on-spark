{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast Forward Review of Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [Installation of Spark](#Installation-of-Spark)\n",
    "* [Spark Context](#Spark-Context)\n",
    "    * [Create A RDD](#Create-A-RDD)\n",
    "    * [Call `collect` on an RDD: Lazy Spark](#Call-collect-on-an-RDD:-Lazy-Spark)\n",
    "    * [Operations on RDDs](#Operations-on-RDDs)\n",
    "    * [Word Examples](#Word-Examples)\n",
    "    * [Key Value Pairs](#Key-Value-Pairs)\n",
    "    * [word count  `reduceByKey()`](#WORD-COUNT!)\n",
    "    * [Nested Syntax](#Nested-Syntax)\n",
    "    * [Using Cache](#Using-Cache)\n",
    "    * [Fun with words](#Fun-with-words)\n",
    "    * [DataFrames](#DataFrames)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation of Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Apache Spark as per instructions\n",
    "\n",
    "Refer the `README.md` file below \n",
    "\n",
    "https://github.com/nipunsadvilkar/hands-on-spark/blob/master/README.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Spark Context\n",
    "\n",
    "If you have configured Apache Spark on your machine successfully then go ahead and type command `pyspark` to open up Ipython notebook in your browser.\n",
    "\n",
    "Since we initiated from `pyspark` command, instance of `SparkContext` will be available to us. \n",
    "If you have followed another method then use `findspark`. Initiating `SparkContext` in that case would be as follows:\n",
    "\n",
    "```python\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext()\n",
    "```\n",
    "\n",
    "> you may need to pass `spark_home` path to `init` method call\n",
    "\n",
    "Example:\n",
    "\n",
    "`findspark.init(spark_home='/Users/nipunsadvilkar/tools/spark-2.2.1-bin-hadoop2.7')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test to see if you have access to `sc` variable which is `SparkContext` instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.17.45:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting with simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "385"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]).map(lambda x: x**2).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Create A RDD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.rdd.RDD'>\n"
     ]
    }
   ],
   "source": [
    "wordsList = ['cat', 'elephant', 'rat', 'rat', 'cat']\n",
    "# splitting into 4 slices\n",
    "wordsRDD = sc.parallelize(wordsList, 4)\n",
    "# Print out the type of wordsRDD\n",
    "print(type(wordsRDD))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Call `collect` on an RDD: Lazy Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark is lazy. Until you `collect`, nothing is actually run.\n",
    "\n",
    ">Instead, they just remember the transformations applied to some base dataset (e.g. a file). The transformations are only computed when an action requires a result to be returned to the driver program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat', 'elephant', 'rat', 'rat', 'cat']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsRDD.collect()\n",
    "# nothing goes above it's just returning given list as it is (Stupid Program :-P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations on RDDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the Spark Programming Guide:\n",
    "\n",
    ">RDDs support two types of operations: transformations, which create a new dataset from an existing one, and actions, which return a value to the driver program after running a computation on the dataset.\n",
    "\n",
    "For example,\n",
    "\n",
    "1. `map` is **a transformation** that passes each dataset element through a function and returns a new RDD representing the results.\n",
    "2. `reduce` is **an action** that aggregates all the elements of the RDD using some function and returns the final result to the driver program (although there is also a parallel reduceByKey that returns a distributed dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cats\n"
     ]
    }
   ],
   "source": [
    "def makePlural(word):\n",
    "    return word + 's'\n",
    "\n",
    "print(makePlural('cat'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Notice that above function doesnt change any state it takes something, does transformation and returns something else"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform one RDD into another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cats\n",
      "['cats', 'elephants']\n"
     ]
    }
   ],
   "source": [
    "pluralRDD = wordsRDD.map(makePlural)\n",
    "print(pluralRDD.first())\n",
    "print(pluralRDD.take(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cats']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pluralRDD.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cats', 'elephants', 'rats', 'rats', 'cats']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pluralRDD.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Look at sparkUI and you'll see `wordsRDD` is running this `map` -> `runJob` entirely on 4 different thread on my machine. Which is actually an overkill but it's just for demonstartion!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Key Value Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cat', 1), ('elephant', 1), ('rat', 1), ('rat', 1), ('cat', 1)]\n"
     ]
    }
   ],
   "source": [
    "wordPairs = wordsRDD.map(lambda w: (w, 1))\n",
    "print(wordPairs.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### WORD COUNT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cat', 2), ('elephant', 1), ('rat', 2)]\n"
     ]
    }
   ],
   "source": [
    "wordsList = ['cat', 'elephant', 'rat', 'rat', 'cat']\n",
    "wordsRDD = sc.parallelize(wordsList, 4)\n",
    "wordCountsCollected = (wordsRDD\n",
    "                       .map(lambda w: (w, 1))\n",
    "                       .reduceByKey(lambda x,y: x+y)\n",
    "                       .collect())\n",
    "print(wordCountsCollected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Tons of shuffling](https://databricks.gitbooks.io/databricks-spark-knowledge-base/content/images/reduce_by.png)\n",
    "\n",
    "\n",
    "> Spark Framework decide in what fashion to split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4) PythonRDD[58] at RDD at PythonRDD.scala:48 []\n",
      " |  MapPartitionsRDD[57] at mapPartitions at PythonRDD.scala:436 []\n",
      " |  ShuffledRDD[56] at partitionBy at NativeMethodAccessorImpl.java:0 []\n",
      " +-(4) PairwiseRDD[55] at reduceByKey at <ipython-input-31-8b78b347e2c9>:3 []\n",
      "    |  PythonRDD[54] at reduceByKey at <ipython-input-31-8b78b347e2c9>:3 []\n",
      "    |  ParallelCollectionRDD[28] at parallelize at PythonRDD.scala:489 []\n"
     ]
    }
   ],
   "source": [
    "print((wordsRDD\n",
    "    .map(lambda w: (w, 1))\n",
    "    .reduceByKey(lambda x,y: x+y)).toDebugString().decode('UTF-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsList = ['cat', 'elephant', 'rat', 'rat', 'cat']\n",
    "wordsRDD = sc.parallelize(wordsList, 4)\n",
    "wordsRDD.count()\n",
    "\n",
    "# again until `count` is being called it logs what needs to be called one after the another\n",
    "# and once `count` gets called it runs all those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# entire program from start will run again\n",
    "wordsRDD.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[63] at parallelize at PythonRDD.scala:489"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#default storage level (MEMORY_ONLY)\n",
    "wordsRDD.cache()#nothing done this is still lazy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parallelize is rerun and cached because we told it to cache\n",
    "wordsRDD.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this `sc.parallelize` is not rerun in this case\n",
    "wordsRDD.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Checkout spark UI you'll see it's being cached\n",
    "\n",
    "\n",
    "![cached](../img/cached.png \"Cached\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where is this useful: it is when you have branching parts or loops, so that you dont do things again and again. Spark, being \"lazy\" will rerun the chain again. So `cache` or `persist` serves as a checkpoint, breaking the RDD chain or the *lineage*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat': 'mammal',\n",
       " 'elephant': 'mammal',\n",
       " 'heron': 'bird',\n",
       " 'owl': 'bird',\n",
       " 'rat': 'mammal'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "birds_list=['heron','owl']\n",
    "anim_list = wordsList + birds_list\n",
    "animaldict={}\n",
    "for e in wordsList:\n",
    "    animaldict[e]='mammal'\n",
    "for e in birds_list:\n",
    "    animaldict[e]='bird'\n",
    "animaldict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 2\n"
     ]
    }
   ],
   "source": [
    "animsrdd = sc.parallelize(anim_list, 4)\n",
    "animsrdd.cache()\n",
    "# below runs the whole chain but causes cache to be populated\n",
    "mammalcount=animsrdd.filter(lambda w: animaldict[w]=='mammal').count()\n",
    "# now only the filter is carried out\n",
    "birdcount=animsrdd.filter(lambda w: animaldict[w]=='bird').count()\n",
    "print(mammalcount, birdcount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> that second filter operation for `birdcount` didn't run all the way from the top. It took that cached `animsrdd` and ran the operation which saved computation and in a way speeded up the things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fun with words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read http://spark.apache.org/docs/latest/programming-guide.html ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords=[e.strip() for e in open(\"../data/english.stop.txt\").readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "juliusrdd=sc.textFile(\"../data/shakes/juliuscaesar.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21245"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "juliusrdd.flatMap(lambda line: line.split()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1599',\n",
       " 'the',\n",
       " 'tragedy',\n",
       " 'of',\n",
       " 'julius',\n",
       " 'caesar',\n",
       " 'by',\n",
       " 'william',\n",
       " 'shakespeare',\n",
       " 'dramatis']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(juliusrdd.flatMap(lambda line: line.split())\n",
    " .map(lambda word: word.strip().lower())\n",
    "  .take(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz\n",
    "\n",
    "### Will above cell run all the operations from start or just take input from previous line and do operation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1599',\n",
       " 'tragedy',\n",
       " 'julius',\n",
       " 'caesar',\n",
       " 'william',\n",
       " 'shakespeare',\n",
       " 'dramatis',\n",
       " 'personae',\n",
       " 'julius',\n",
       " 'caesar,',\n",
       " 'roman',\n",
       " 'statesman',\n",
       " 'general',\n",
       " 'octavius,',\n",
       " 'triumvir',\n",
       " \"caesar's\",\n",
       " 'death,',\n",
       " 'augustus',\n",
       " 'caesar,',\n",
       " 'emperor']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(juliusrdd.flatMap(lambda line: line.split())\n",
    " .map(lambda word: word.strip().lower())\n",
    " .filter(lambda word: word not in stopwords)\n",
    " .take(20)\n",
    ")\n",
    "\n",
    "# take is a reducer i.e., \"Action\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1599', 1),\n",
       " ('tragedy', 1),\n",
       " ('julius', 1),\n",
       " ('caesar', 1),\n",
       " ('william', 1),\n",
       " ('shakespeare', 1),\n",
       " ('dramatis', 1),\n",
       " ('personae', 1),\n",
       " ('julius', 1),\n",
       " ('caesar,', 1),\n",
       " ('roman', 1),\n",
       " ('statesman', 1),\n",
       " ('general', 1),\n",
       " ('octavius,', 1),\n",
       " ('triumvir', 1),\n",
       " (\"caesar's\", 1),\n",
       " ('death,', 1),\n",
       " ('augustus', 1),\n",
       " ('caesar,', 1),\n",
       " ('emperor', 1)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(juliusrdd.flatMap(lambda line: line.split())\n",
    " .map(lambda word: word.strip().lower())\n",
    " .filter(lambda word: word not in stopwords)\n",
    " .map(lambda word: (word, 1))\n",
    " .take(20)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('him-let', 1),\n",
       " ('fire!', 1),\n",
       " ('matter;', 1),\n",
       " ('head', 2),\n",
       " ('dark', 1),\n",
       " ('avoided', 1),\n",
       " (\"fear'd\", 2),\n",
       " ('dull,', 1),\n",
       " ('choked', 2),\n",
       " ('tents', 1),\n",
       " (\"engender'd\", 1),\n",
       " ('benefit', 1),\n",
       " (\"bay'd,\", 1),\n",
       " ('brutus.', 211),\n",
       " ('law', 1),\n",
       " ('behold', 4),\n",
       " ('proof', 3),\n",
       " ('aside.', 1),\n",
       " ('coming,', 1),\n",
       " ('arose', 1)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(juliusrdd.flatMap(lambda line: line.split())\n",
    " .map(lambda word: word.strip().lower())\n",
    " .filter(lambda word: word not in stopwords)\n",
    " .map(lambda word: (word, 1))\n",
    " .reduceByKey(lambda a, b: a + b)\n",
    " .take(20)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('brutus.', 211),\n",
       " ('cassius.', 152),\n",
       " ('thou', 107),\n",
       " ('caesar', 96),\n",
       " ('brutus', 75),\n",
       " ('antony.', 73),\n",
       " ('citizen.', 68),\n",
       " ('good', 66),\n",
       " ('caesar.', 62),\n",
       " ('thy', 54),\n",
       " ('brutus,', 54),\n",
       " ('caesar,', 46),\n",
       " ('\"', 44),\n",
       " ('casca.', 44),\n",
       " ('you,', 41),\n",
       " ('men', 41),\n",
       " (\"caesar's\", 40),\n",
       " ('enter', 40),\n",
       " ('lucius.', 38),\n",
       " ('cassius,', 38)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(juliusrdd.flatMap(lambda line: line.split())\n",
    " .map(lambda word: word.strip().lower())\n",
    " .filter(lambda word: word not in stopwords)\n",
    " .map(lambda word: (word, 1))\n",
    " .reduceByKey(lambda a, b: a + b)\n",
    " .takeOrdered(20, lambda x: -x[1]) # negative of second element - descending sort\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10472aa90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "captions, counts=zip(*juliusrdd.flatMap(lambda line: line.split())\n",
    " .map(lambda word: word.strip().lower())\n",
    " .filter(lambda word: word not in stopwords)\n",
    " .map(lambda word: (word, 1))\n",
    " .reduceByKey(lambda a, b: a + b)\n",
    " .takeOrdered(20, lambda x: -x[1])\n",
    ")\n",
    "pos = np.arange(len(counts))\n",
    "plt.bar(pos, counts);\n",
    "plt.xticks(pos, captions, rotation=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run it on all plays of Shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakesrdd=sc.textFile(\"../data/shakes/*.txt\", minPartitions=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1601',\n",
       " 'AS YOU LIKE IT',\n",
       " '',\n",
       " 'by William Shakespeare',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'DRAMATIS PERSONAE.',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakesrdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mistempered', 1),\n",
       " ('mad', 58),\n",
       " ('crocodile.--', 1),\n",
       " ('[draws,', 1),\n",
       " ('suppliest', 1),\n",
       " ('head', 101),\n",
       " ('being:', 1),\n",
       " ('warning', 4),\n",
       " ('lapsed', 1),\n",
       " ('lease', 1),\n",
       " (\"prince's\", 8),\n",
       " ('weakens,', 1),\n",
       " ('elected', 2),\n",
       " ('nobleman,', 1),\n",
       " ('done:', 4),\n",
       " ('serve.', 1),\n",
       " ('misprised.', 1),\n",
       " ('cost', 9),\n",
       " ('liest,', 4),\n",
       " (\"lying'st\", 1),\n",
       " ('converting', 1),\n",
       " ('wounds,', 5),\n",
       " ('embarquements', 1),\n",
       " ('window', 5),\n",
       " ('impotence', 1),\n",
       " (\"hermia's:\", 2),\n",
       " ('pluck', 42),\n",
       " ('invention', 3),\n",
       " (\"cousin.'\", 1),\n",
       " ('remorseful', 1)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(shakesrdd.flatMap(lambda line: line.split())\n",
    " .map(lambda word: word.strip().lower())\n",
    " .filter(lambda word: word not in stopwords)\n",
    " .map(lambda word: (word, 1))\n",
    " .reduceByKey(lambda a, b: a + b)\n",
    " .take(30)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SparkContext.wholeTextFile`...\n",
    "\n",
    ">lets you read a directory containing multiple small text files, and returns each of them as (filename, content) pairs - which is called **PairedRDD**. This is in contrast with textFile, which would return one record per line in each file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Spark DataFrame to Pandas\n",
    "\n",
    "`pandas_df = spark_df.toPandas()`\n",
    "\n",
    "Create a Spark DataFrame from Pandas\n",
    "\n",
    "```python\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "spark_df = sqlContext.createDataFrame(pandas_df)\n",
    "```\n",
    "\n",
    "> **KEEP in mind that it MUST fit in memory.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz\n",
    "    \n",
    "### Would you be able to create new column in spark DataFrame as you do in pandas DataFrame? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's move on to the exercise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
